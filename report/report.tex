\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% new commands
\newcommand{\given}{\,|\,}
\newcommand{\I}{\mathbb{I}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{RANSAC With Likelihood Sampling}

\author{Xiangyu Kong\\
   University of Toronto\\
   1002109620 kongxi16}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   RANSAC (RAndom SAmple Consensus) has been a popular algorithm in computer vision for fitting a model to data points containing outliers \cite{RansacPaper}.
   Traditional RANSAC algorithm uses random sampling to choose data points, and use these data points to generate models \cite{RansacSlides}.
   Instead of sampling randomly, we explore the possibility of sampling based on the likelihoods of the data point to be inliers.
   A previously developed form of RANSAC, BAYSAC \cite{BaysacPaper}, is used in the experiment.
   Experiments were conducted on the noisy circle finding problem \cite{NoisyCircleFindingProblem} in order to demonstrate the differences and similarities between BAYSAC and RANSAC.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

%-------------------------------------------------------------------------
\subsection{RANSAC}

RANSAC (RAndom SAmple Consensus) is mainly used in computer vision for fitting a model to data points containing outliers \cite{RansacPaper}.
In general, RANSAC algorithm follows the algorithm given in Algorithm~\ref{algo:ransac}:

\begin{algorithm}
   \caption{RANSAC($num\_iter$, $threshold$)}\label{algo:ransac}
   \begin{algorithmic}[1]
      \State $t = 0$, $\I = \{\}$
      \While{$t < num\_iter$ and $\I.size() < desired\_size$}
      \State Randomly Sample dataset $H_{i}$ of size ($n + 1$).
      \State Fit a polynomial $model$ of degree $n$.
      \If{$\forall j \in H_{i}$, $dist(model, j) < threshold$}
      \State $\I = \I \cup H_{i}$.
      \EndIf
      \State $t ++$
      \EndWhile
      \State\Return the fitted $model$ using all points in $\I$.
   \end{algorithmic}
\end{algorithm}


%-------------------------------------------------------------------------
\subsection{Problem Definition}

The problem of noisy circle finding problem is defined as follows. Given two input arrays of pixel locations where $X = [x_{1}, x_{2}, \dots, x_{n}]$, $Y = [y_{1}, y_{2}, \dots, y_{n}]$, $n \geq 3$, find a best-fit circle with center $(x, y)$, and its radius $r$ \cite{NoisyCircleFindingProblem}. An example of the problem is shown in Figure~\ref{fig:circle_finding}

\begin{figure}[!ht]
   \begin{center}
      \includegraphics[width=0.6\linewidth]{./images/noisy_circle.png}
   \end{center}
   \caption{Example of Circle Finding Problem}
   \label{fig:circle_finding}
\end{figure}


%------------------------------------------------------------------------
\section{Related Work}
\label{section:related_work}


%-------------------------------------------------------------------------
\subsection{Noisy Circle Finding Problem}

The noisy circle finding problem has been a classic exercise for computer vision students and an ongoing research topic for scholars. There are many approaches to solving this problem, including RANSAC, Patch Matching, Neural Network, etc.

For our experiment, we adopted and extended on an existing RANSAC circle detection project \cite{RansacGitHub}. The original project uses RANSAC with a twist. Instead of counting the number of inliers, the author chooses the model that has the minimum distance to all data points. We modified this part back to counting the number of inliers, and extended the class to implement the BAYSAC algorithm described in Section~\ref{section:baysac}.


%-------------------------------------------------------------------------
\subsection{BAYSAC}
\label{section:baysac}

The BAYSAC algorithm \cite{BaysacPaper} first assign all points' likelihoods to be inliers to $0.5$.
For each iteration, it updates the points' likelihoods using Equation~(\ref{eq:1}), where $P_{t}(i \in \I)$ indicates the probability of point $i$ being in the inliers set $\I$ at iteration $t$;
$P(H_{t} \subseteq \I)$ indicates the probability of the sample $H$ at iteration $t$ being a subset of the inlier set $\I$. I.e. for all points in the sample $j \in H_{t}$, $j \in \I$.

\begin{align} \label{eq:1}
   P_{t}(i \in \I)
    & =
   \begin{cases}
      \dfrac{P_{t - 1}(i \in \I) P(H_{t} \not\subseteq \I \given i \in \I)}{P(H_{t} \not\subseteq \I)}
       & i \in H_{t}
      \\
      P_{t - 1}(i \in \I)
       & i \not \in H_{t}
   \end{cases}
\end{align}

To calculate $P(H_{t} \not\subseteq \I \given i \in \I)$ and $P(H_{t} \not\subseteq \I)$, Equation~(\ref{eq:2}) and Equation~(\ref{eq:3}) are used.

\begin{align} \label{eq:2}
   P(H_{t} \not\subseteq \I)
    & = 1 - P(H_{t} \subseteq \I) \nonumber
   \\
    & = 1 - \prod^{}_{j \in H_{t}} P_{t - 1}(j \in \I)
\end{align}

\begin{align} \label{eq:3}
   P(H_{t} \not\subseteq \I \given i \in \I)
    & = 1 - P(H_{t} \subseteq \I \given i \in \I) \nonumber
   \\
    & = 1 - \prod^{}_{j \in H_{t}; j \neq i} P_{t - 1}(j \in \I) \nonumber
   \\
    & = 1 - \dfrac{P(H_{t} \subseteq \I)}{P_{t - 1}(i \in \I)}
\end{align}

Finally, combining Equations~(\ref{eq:2}, \ref{eq:3}) with Equation~(\ref{eq:1}), we derive Equation~(\ref{eq:4})

\begin{align} \label{eq:4}
   P_{t}(i \in \I)
    & =
   \begin{cases}
      \dfrac{P_{t - 1}(i \in \I) - P(H_{t} \subseteq \I)}{1 - P(H_{t} \subseteq \I)}
       & i \in H_{t}
      \\
      P_{t - 1}(i \in \I)
       & i \not \in H_{t}
   \end{cases}
\end{align}


%------------------------------------------------------------------------
\section{Experiment}

%-------------------------------------------------------------------------
\subsection{Algorithm}

Combining the two related work described in the Section~\ref{section:related_work}, the final BAYSAC algorithm can be written as Algorithm~\ref{algo:baysac}, where $dist(model, j)$ is the L2 distance defined by Equation~\ref{eq:5}.

\begin{align} \label{eq:5}
   dist(x_{c}, y_{c}, r_{c}, x_{j}, y_{j}) = | \sqrt{(x_{j} - x_{c})^{2} + (y_{j} - y_{c})^{2}} - r_{c} |
\end{align}

\begin{algorithm}
   \caption{BAYSAC($num\_iter$, $threshold$)}\label{algo:baysac}
   \begin{algorithmic}[1]
      \State $t = 0$, $\I = \{\}$
      \While{$t < num\_iter$ and $\I.size() < desired\_size$}
      \State Sample $H_{t}$ of ($n + 1$) points ordered by highest $P_{t - 1}(i \in \I)$
      \State Fit a polynomial $model$ of degree $n$.
      \If{$\forall j \in H_{t}$, $dist(model, j) < threshold$}
      \State $\I = \I \cup H_{t}$.
      \EndIf
      \State update all points' $P_{t}(i \in \I)$ base on Equation~\ref{eq:4}
      \State $t ++$
      \EndWhile
      \State\Return the fitted $model$ using all points in $\I$.
   \end{algorithmic}
\end{algorithm}


%------------------------------------------------------------------------
\section{Conclusions}

%------------------------------------------------------------------------
\pagebreak
{\small
   \bibliographystyle{ieee_fullname}
   \bibliography{reportbib}
}

\end{document}
